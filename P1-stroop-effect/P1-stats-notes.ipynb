{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Notes for Statistics Portion\n",
    "\n",
    "### On Standardizing with Z-Scores\n",
    "\n",
    "Standardization gives you the ability to report on values with respect to the mean in an relative way. From an absolute perspective, it would go something like this: \"I have a score of 370\" or \"I am ranked 567th out of the population\". Relatively speaking, you can instead say this: \"I rank above 95% of the entire population, or I'm in the 95th percentile\".\n",
    "\n",
    "Given the mean ($\\bar{x}$), SD ($\\sigma$), the Z-score is taken by $$\\frac{(x-\\bar{x})}{\\sigma}$$\n",
    "\n",
    "This shows the number of standard deviations away from the mean the value is. Using this, given the distribution is Gaussian, you can then tell what % of values are below/above the value in question using a z-score table. Note: you can also do this via a PDF function which requires some calculus to get the area below the PDF.\n",
    "\n",
    "\n",
    "### On the Central Limit Theorem\n",
    "\n",
    "CLT states that given a statistic calculated from several samples of size $n$ from a population (say, the mean), the mean of the sampling distribution ($\\bar{x}$) will roughly equal the mean of the population ($\\mu$). Also, the sampling error ($SE$) is equal to $$\\frac{\\sigma}{\\sqrt{n}}$$\n",
    "\n",
    "which is to say that the standard deviation of this sampling distribution is equal to the standard distribution of the population adjusted for the size of the sample you've been taking ($n$). The resulting sampling distribution will also turn out roughly normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Estimating Population Mean Given Sample Mean after an Intervention ($\\bar{x}_I$)\n",
    "\n",
    "<img src=\"files/images/confidence-interval.png\"></img>\n",
    "\n",
    "Given a sample mean ($\\bar{x}_I$), you can estimate the population mean within a certain confidence interval given some assumptions. \n",
    "\n",
    "- First is to assume that $\\bar{x}_I$ falls within 1.96 SDs of the sampling distribution mean.\n",
    "- Second is that given the first, then the new population mean $\\mu_I$ will fall within 1.96 SDs of $\\bar{x}_I$ since most sample means (95% to be exact) will lie within 1.96 SDs away from $\\bar{x}_I$\n",
    "\n",
    "Then we can predict with 95% confidence that $\\mu_I$ is given by:\n",
    "\n",
    "\n",
    "$\\bar{x}_I + 1.96 * \\frac{\\sigma}{\\sqrt{n}}$ > $\\mu_I$ > $\\bar{x}_I - 1.96 * \\frac{\\sigma}{\\sqrt{n}}$\n",
    "\n",
    "\n",
    "In this situation SD of the sample = SE = $\\frac{\\sigma}{\\sqrt{n}}$. \n",
    "\n",
    "\n",
    "Note: $\\frac{2\\sigma}{\\sqrt{n}}$ = margin of error\n",
    "Actually, more generally it's $\\frac{Z*\\sigma}{\\sqrt{n}}$\n",
    "\n",
    "\n",
    "### On Critical Values for Z-Scores\n",
    "\n",
    "Critical values depend on the confidence level you choose. If you picked 95% then the critical value is given by \"how many standard deviations away from the mean contain 95% of the data\". On a z-score table you would look up the z-score for 0.05 for 95% CI (it's 1.96).\n",
    "\n",
    "### On p-values and $\\alpha$ Levels\n",
    "\n",
    "<img src=\"files/images/p-value-alpha-levels.png\"></img>\n",
    "\n",
    "Given a sample mean $\\bar{x}$, we can see whether it is significant at certain alpha levels or p-values. \n",
    "\n",
    "- First we take the z-score of that value, signifying what % of sample means fall below the $\\bar{x}$ in question.\n",
    "- Next given that z-score, we compare it to what we call the **z critical values** at certain alpha levels.\n",
    "- The higher the z-score, the likelier it is that the sample with its $\\bar{x}$ did not occur as a result of chance. If a sample mean falls within the orange region, then there is the possibility that the sample (with its mean) was just drawn from the population by chance.\n",
    "\n",
    "The different alpha levels help us decide how sure we are that the sample mean $\\bar{x}$ did not occur due to chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Hypothesis Testing\n",
    "\n",
    "Two-tailed: split the critical region into two and put it on both sides of the sampling distribution (i.e. $\\alpha$ = 0.05 means 2.5% on both sides of the dist).\n",
    "\n",
    "Given a sample, you then see how far away from the population mean the sample's mean is. If it is far enough on either side, you reject the null hypothesis (that there is no difference between the old $\\mu$ and new $\\mu_T$ (with treatment)).\n",
    "- One-tailed means a significant difference on one end only, two-tailed means you don't care about the direction in which it is different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On t-tests, Where $\\mu$ and $\\sigma$ Unknown (i.e. we only have a sample, not data on the population)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
